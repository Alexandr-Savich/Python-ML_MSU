{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=pd.read_csv('train.csv',delimiter=',')\n",
    "test=pd.read_csv('test.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=words['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think they really let the quality of the DVD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sorry but this is just awful. I have told ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Japenese sense of pacing, editing and musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In the '60's/'70's, David Jason was renowned f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Hail The Woman\" is one of the most moving fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>39995</td>\n",
       "      <td>When you come across a gem of a movie like thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>39996</td>\n",
       "      <td>I don't often go out of my way to write commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>39997</td>\n",
       "      <td>This is an extremely silly and little seen fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>39998</td>\n",
       "      <td>Just saw the movie, and the scary thing was, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>39999</td>\n",
       "      <td>...though for a film that seems to be trying t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             review\n",
       "0               0  I think they really let the quality of the DVD...\n",
       "1               1  I'm sorry but this is just awful. I have told ...\n",
       "2               2  The Japenese sense of pacing, editing and musi...\n",
       "3               3  In the '60's/'70's, David Jason was renowned f...\n",
       "4               4  \"Hail The Woman\" is one of the most moving fil...\n",
       "...           ...                                                ...\n",
       "39995       39995  When you come across a gem of a movie like thi...\n",
       "39996       39996  I don't often go out of my way to write commen...\n",
       "39997       39997  This is an extremely silly and little seen fil...\n",
       "39998       39998  Just saw the movie, and the scary thing was, t...\n",
       "39999       39999  ...though for a film that seems to be trying t...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.array(words)\n",
    "t=np.array(test)\n",
    "w1=[]\n",
    "w2=[]\n",
    "for i in range(40000):\n",
    "    w1.append(w[i][1])\n",
    "for i in range(10000):\n",
    "    w2.append(t[i][1])\n",
    "w=np.array(w1)\n",
    "t=np.array(w2)\n",
    "for i in range(len(w)):\n",
    "    w[i] = re.sub('<br\\s/>',' ',w[i],flags=re.IGNORECASE)\n",
    "for i in range(len(t)):\n",
    "    t[i] = re.sub('<br\\s/>',' ',t[i],flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=0.005,\n",
       "                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                      'afterwards', 'again', 'against', 'all',\n",
       "                                      'almost', 'alone', 'along', 'already',\n",
       "                                      'also', 'although', 'always', 'am',\n",
       "                                      'among', 'amongst', 'amoungst', 'amount',\n",
       "                                      'an', 'and', 'another', 'any', 'anyhow',\n",
       "                                      'anyone', 'anything', 'anyway',\n",
       "                                      'anywhere', ...}))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vector = TfidfVectorizer(lowercase=True, stop_words=ENGLISH_STOP_WORDS,\n",
    "                             analyzer='word',min_df = 0.005)\n",
    "vector.fit(w)\n",
    "vector.fit(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=0.005, ngram_range=(2, 2),\n",
       "                stop_words=frozenset({'a', 'about', 'above', 'across', 'after',\n",
       "                                      'afterwards', 'again', 'against', 'all',\n",
       "                                      'almost', 'alone', 'along', 'already',\n",
       "                                      'also', 'although', 'always', 'am',\n",
       "                                      'among', 'amongst', 'amoungst', 'amount',\n",
       "                                      'an', 'and', 'another', 'any', 'anyhow',\n",
       "                                      'anyone', 'anything', 'anyway',\n",
       "                                      'anywhere', ...}))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector2 = TfidfVectorizer(lowercase=True, stop_words=ENGLISH_STOP_WORDS,\n",
    "                             analyzer='word',ngram_range=(2, 2),min_df = 0.005)\n",
    "vector2.fit(w)\n",
    "vector2.fit(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector2.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think they really let the quality of the DVD production get away from them. I rented this DVD from 2 movie stores and the second time I finally got it to play on the 3rd DVD player I tried.  Anyone else have this issue? It's really hard to give the film an un-biased review after going through such a hassle to play it. For one, I've never seen a Finnish horror film before so I was sort of bummed that the movie was done in English. Also since it's never made clear what is wrong with Sarah, she just came off as retarded and therefore I really just hoped someone would shoot her in the face and make all the horrific happenings go away.\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пунктуация ? ! как параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = np.zeros(len(w))\n",
    "for i in range (len(ask)):\n",
    "    ask[i] = w[i].count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask1 = np.zeros(len(t))\n",
    "for i in range (len(ask1)):\n",
    "    ask1[i] = t[i].count('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.zeros(len(w))\n",
    "for i in range (len(v)):\n",
    "    v[i] = w[i].count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.zeros(len(t))\n",
    "for i in range (len(v1)):\n",
    "    v1[i] = t[i].count('!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество слов как параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a1 = np.zeros(len(w))\n",
    "#for i in range (len(a1)):\n",
    "#    a1[i] = len(w[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at1 = np.zeros(len(t))\n",
    "#for i in range (len(at1)):\n",
    "#    at1[i] = len(t[i].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество символов как параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.zeros(len(w))\n",
    "for i in range (len(a2)):\n",
    "    a2[i] = len(w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "at2 = np.zeros(len(t))\n",
    "for i in range (len(at2)):\n",
    "    at2[i] = len(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание таблицы из параметров-слов, пунктуации и количества слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vector.transform(w)\n",
    "z=vector.transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(x.toarray())\n",
    "dft=pd.DataFrame(z.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слияние двух таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = vector2.transform(w)\n",
    "z2 = vector2.transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(x2.toarray())\n",
    "dft2=pd.DataFrame(z2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2.columns = np.arange(len(list(dft2)))+len(list(dft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = np.arange(len(list(df2)))+len(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft.join(dft2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['?'] = pd.Series(ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['?'] = pd.Series(ask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['!'] = pd.Series(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['!'] = pd.Series(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['words'] = pd.Series(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dft['words'] = pd.Series(at1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lens'] = pd.Series(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['lens'] = pd.Series(at2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "dft = scaler.transform(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns=[cols])\n",
    "dft = pd.DataFrame(dft, columns=[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление квадратов значений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq = df.copy(deep=True)\n",
    "dfq = np.square(dfq)\n",
    "dfq.columns = np.arange(len(list(df)))+len(list(df))\n",
    "df = df.join(dfq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftq = dft.copy(deep=True)\n",
    "dftq = np.square(dftq)\n",
    "dftq.columns = np.arange(len(list(dft)))+len(list(dft))\n",
    "dft = dft.join(dftq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем регрессию (потом -- Байеса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test,label_train, label_test = train_test_split(df,label, test_size=0.2, shuffle=True, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg1 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(df, label)\n",
    "logreg1.fit(df_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = logreg.predict(df)\n",
    "y_pred_test = logreg.predict(dft)\n",
    "\n",
    "Y_pred_train = logreg1.predict(df_train)\n",
    "Y_pred_test = logreg1.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=132, shuffle=True)\n",
      "TRAIN: [    0     1     2 ... 39997 39998 39999] TEST: [    3    16    19 ... 39983 39990 39992]\n",
      "0.8789855964545119\n",
      "TRAIN: [    1     2     3 ... 39997 39998 39999] TEST: [    0     4     5 ... 39991 39995 39996]\n",
      "0.87865055387714\n",
      "TRAIN: [    0     1     3 ... 39997 39998 39999] TEST: [    2     9    13 ... 39986 39987 39993]\n",
      "0.8765571913929785\n",
      "TRAIN: [    0     1     2 ... 39995 39996 39999] TEST: [   11    12    15 ... 39994 39997 39998]\n",
      "0.8764211566979733\n",
      "TRAIN: [    0     2     3 ... 39996 39997 39998] TEST: [    1     6     7 ... 39984 39989 39999]\n",
      "0.8918784255107125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "R = df.copy(deep=True)\n",
    "S = label.copy(deep=True)\n",
    "kf = KFold(n_splits=5, random_state=132, shuffle=True)\n",
    "kf.get_n_splits(R)\n",
    "\n",
    "p=0.\n",
    "print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split(R):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    R_train, R_test = R.iloc[train_index], R.iloc[test_index]\n",
    "    \n",
    "    S_train, S_test = S.iloc[train_index], S.iloc[test_index]\n",
    "    logregK = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    logregK.fit(R_train, S_train)\n",
    "    S_pred_test = logregK.predict(R_test)\n",
    "    p=p+f1_score(S_test, S_pred_test)\n",
    "    print(f1_score(S_test, S_pred_test))\n",
    "    logregK=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=13, shuffle=True)\n",
      "TRAIN: [    0     1     2 ... 39997 39998 39999] TEST: [    5     8    11 ... 39982 39990 39995]\n",
      "0.8767021539985146\n",
      "TRAIN: [    0     1     2 ... 39997 39998 39999] TEST: [    6     7    14 ... 39983 39988 39994]\n",
      "0.8712026110971629\n",
      "TRAIN: [    0     1     2 ... 39996 39998 39999] TEST: [    3     9    12 ... 39989 39993 39997]\n",
      "0.8846487424111015\n",
      "TRAIN: [    0     1     2 ... 39996 39997 39999] TEST: [    4    13    21 ... 39984 39991 39998]\n",
      "0.8808172531214529\n",
      "TRAIN: [    3     4     5 ... 39995 39997 39998] TEST: [    0     1     2 ... 39992 39996 39999]\n",
      "0.8784605834885163\n"
     ]
    }
   ],
   "source": [
    "R = df.copy(deep=True)\n",
    "S = label.copy(deep=True)\n",
    "kf = KFold(n_splits=5, random_state=13, shuffle=True)\n",
    "kf.get_n_splits(R)\n",
    "print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split(R):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    R_train, R_test = R.iloc[train_index], R.iloc[test_index]\n",
    "    \n",
    "    S_train, S_test = S.iloc[train_index], S.iloc[test_index]\n",
    "    logregK = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    logregK.fit(R_train, S_train)\n",
    "    S_pred_test = logregK.predict(R_test)\n",
    "    p=p+f1_score(S_test, S_pred_test)\n",
    "    print(f1_score(S_test, S_pred_test))\n",
    "    logregK=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794324268050066"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8820398564178734"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(label_test, Y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5146"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y_pred_test !=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Test metrics\n",
      "[[3484  498]\n",
      " [ 455 3563]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('New Test metrics')\n",
    "print(confusion_matrix(label_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Test metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      3982\n",
      "           1       0.88      0.89      0.88      4018\n",
      "\n",
      "    accuracy                           0.88      8000\n",
      "   macro avg       0.88      0.88      0.88      8000\n",
      "weighted avg       0.88      0.88      0.88      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('New Test metrics')\n",
    "print(classification_report(label_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "[[18527  1540]\n",
      " [ 1303 18630]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Train metrics')\n",
    "print(confusion_matrix(label, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     20067\n",
      "           1       0.92      0.93      0.93     19933\n",
      "\n",
      "    accuracy                           0.93     40000\n",
      "   macro avg       0.93      0.93      0.93     40000\n",
      "weighted avg       0.93      0.93      0.93     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Train metrics')\n",
    "print(classification_report(label, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train metrics\n",
      "[[14960  1125]\n",
      " [  989 14926]]\n"
     ]
    }
   ],
   "source": [
    "print('New Train metrics')\n",
    "print(confusion_matrix(label_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train metrics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93     16085\n",
      "           1       0.93      0.94      0.93     15915\n",
      "\n",
      "    accuracy                           0.93     32000\n",
      "   macro avg       0.93      0.93      0.93     32000\n",
      "weighted avg       0.93      0.93      0.93     32000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('New Train metrics')\n",
    "print(classification_report(label_train, Y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame({'ID': np.arange(10000),'Predicted': y_pred_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Predicted\n",
       "0        0          0\n",
       "1        1          1\n",
       "2        2          0\n",
       "3        3          1\n",
       "4        4          0\n",
       "...    ...        ...\n",
       "9995  9995          1\n",
       "9996  9996          0\n",
       "9997  9997          1\n",
       "9998  9998          1\n",
       "9999  9999          1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('IMDBout19TFit0025.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
